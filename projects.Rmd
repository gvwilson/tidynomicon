---
title: "Projects"
output: md_document
permalink: /projects/
questions:
  - "FIXME"
objectives:
  - "FIXME"
keypoints:
  - "FIXME"
---

```{r echo=FALSE}
library(tidyverse)
```

Mistakes were made in [the previous tutorial](../cleanup/).
It would be [hubris](../glossary/#hubris) to believe that we will not make more as we continue to clean this data.
What will guide us safely through these dark caverns and back into the light of day?

The answer is testing.
We must test our assumptions, test our code, test our very *being* if we are to advance.
Luckily for us,
R provides tools for this purpose not unlike those available in Python.
In order to use them,
we must first venture into the greater realm of packaging in R.

## Packaging

Unlike Python,
with its confusing plethora of packaging tools,
R has one way to do it.
Before converting our project into a package,
we will explore what a package should contain.

### `DESCRIPTION`

The text file `DESCRIPTION` (with no suffix) holds most of the package's metadata,
including a description of what it,
who wrote it,
and what other packages it requires to run.

### NAMESPACE

This file, whose name also has no extension, contains the names of everything exported from the package
(i.e., everything that is visible to the outside world).
RStudio does a good job of creating and managing it,
so we will not discuss it further.

### `.Rbuildignore`

Just as `.gitignore` tells Git what files in a project to ignore,
`.Rbuildignore` tells RStudio which files it doesn't need to worry about
when building a package from source.

### The `R` Directory

The R source for the package should all go in this directory.

Explain that packages are bytecode (unlike Python).

This is why we put functions in the `R` directory, not scripts.
When an R script (or an RMarkdown file) is run in the console or the IDE, its code is executed as you'd expect.
In an R package, the code is only run when the package is built.

But then how to load other libraries?
`library(tidyverse)` won't work because that's executed during build,
so we can't be sure the libraries will be loaded when our package is used.
The solution is to use `package::function` to refer to things.

And no, you can't use sub-directories...

### The `data` Directory

As you would expect, this is where data goes.
In order for it to be loadable, it must be saved in `.rda` format.
(and expect to eventually use `.feather` format).
Use `save` and `load`,
or better yet,
`usethis::use_data(object, overwrite = TRUE)` to save objects
and then load them with the package.

Use `LazyData: TRUE` in `DESCRIPTION` so that datasets are only loaded on demand.

Put raw data in `inst/extdata` (`inst` is for extra files that you want installed).
Use `system.file("extdata", "2012.csv", package = "testdat", mustWork = TRUE)` to get the filename after installation.

### The `man` Directory

This is where manual pages go.
The bad news is, they have to be in a sort-of-LaTeX format.
The good news is,
we can embed comments in our source code and use roxygen2 to extract these and format them as `.Rd` files.

### The `tests` Directory

We've already met this:
it should contain files called `test_group.R`,
each of which should contain functions called `test_feature`,
where "group" and "feature" are memorable names for the group of tests in the file
and the specific aspect of the code that's probably going to fail in an unanticipated way when it matters most.

## Creating a Package

We cannot turn this tutorial into an R package because we're building as a website, not as a package.
Instead, we will create an R package called `unicefdata`.

- Run wizard

```{r echo=FALSE, fig.cap="RStudio Project Creation Wizard"}
knitr::include_graphics("../files/rstudio-project-creation-wizard.png")
```

- Then add the same `README.md`, `LICENSE.md`, `CONDUCT.md`, and `CITATION.md` used for all projects
- And remove `R/hello.R` and `man/hello.Rd` (documentation)

Copy our data tidying script into `R/tidy_datasets_start.R`
- Actually copied it into `R/tidy_datasets.R`, then had to make so many changes that we want to show several versions

FIXME: show file here

Edit `DESCRIPTION`:
- change the `Title`, `Author`, `Maintainer`, and `Description`
- change `License` to `MIT`
- go to the `Build` tab in RStudio and run 'Check

```
* checking top-level files ... NOTE
Non-standard files/directories found at top level:
  ‘CITATION.md’ ‘CONDUCT.md’ ‘LICENSE.md’
...
Found the following CITATION file in a non-standard place:
  CITATION.md
Most likely ‘inst/CITATION’ should be used instead.
```

- A bit of searching and we rearrange as follows:
  - `LICENSE.md` becomes `LICENSE` with no extension
  - `DESCRIPTION` entry updated to `License: MIT + file LICENSE`
  - add a line to `.Rbuildignore` for `CITATION.md` and `CONDUCT.md`

- Solves that problem but now:

```
checking for missing documentation entries ... WARNING
Undocumented code objects:
  ‘tidy_infant_hiv’
All user-level objects in a package should have documentation entries.
```

Put the following at the head of `tidy_datasets_documented.R`

```
#' Clean up and share some data from UNICEF on infant HIV rates and maternal mortality.
#'
#' @author Greg Wilson, \email{greg.wilson@rstudio.com}

#' Tidy up the infant HIV data set.
#'
#' @param src_path path to source file
#'
#' @return a tibble of tidy data
#'
#' @export
```

- The first block documents the file.
- The second documents the function.
- `@export` says "make this visible to the outside world"
- But still get the warning
- Google...
- Need to run `devtools::document()` to regenerate the documentation
- Try this
- Good news and bad news:

```
Updating unicefdata documentation
Loading unicefdata
First time using roxygen2. Upgrading automatically...
Updating roxygen version in /Users/gvwilson/unicefdata/DESCRIPTION
Warning: The existing 'NAMESPACE' file was not generated by roxygen2, and will not be overwritten.
Writing tidy_infant_hiv.Rd
```

- Google...
- Delete `NAMESPACE` and overwrite

```
# Generated by roxygen2: do not edit by hand

export(tidy_infant_hiv)
```

- Go into "Build...More...Configure build tools" and check "Generate documentation with Roxygen"
- Better, but still getting these warnings:

```
tidy_infant_hiv: no visible global function definition for ‘read_csv’
tidy_infant_hiv: no visible global function definition for ‘slice’
tidy_infant_hiv: no visible global function definition for ‘%>%’
tidy_infant_hiv: no visible global function definition for ‘select’
...several more...
tidy_infant_hiv: no visible global function definition for ‘bind_rows’
tidy_infant_hiv: no visible global function definition for ‘arrange’
Undefined global functions or variables:
  %>% Countries ISO3 arrange bind_rows country everything map_dfr
  mutate read_csv rename select slice str_replace year
```

- FIXME: explain when and how libraries loaded
- Use fully-qualified names
- Import functions
- We'll do a mix to show all three options
- Add this to source file

```
#' @import dplyr
#' @importFrom magrittr %>%
```

- Change various calls to use package prefix, e.g.:

```
  raw <- readr::read_csv(src_path, skip = 2, na = c("-"))
  ...
  percents <- sliced %>%
    select(ISO3, Countries) %>%
    purrr::map_dfr(stringr::str_replace, pattern = ">?(\\d+)%", replacement = "\\1") %>%
    purrr::map_dfr(function(col) as.numeric(col) / 100)
```

- Get this error:

```
* checking package dependencies ... ERROR
Namespace dependencies not required: ‘dplyr’ ‘magrittr’

See section ‘The DESCRIPTION file’ in the ‘Writing R Extensions’
manual.
* DONE
Status: 1 ERROR
checking package dependencies ... ERROR
Namespace dependencies not required: ‘dplyr’ ‘magrittr’
```

- Add this to `DESCRIPTION` (getting version numbers with `packageVersion("package")`

```
Imports:
    readr (>= 1.1.0),
    dplyr (>= 0.7.0),
    magrittr (>= 1.5.0),
    purrr (>= 0.2.0),
    rlang (>= 0.3.0),
    stringr (>= 1.3.0)
```

- Still get a warning:

```
checking R code for possible problems ... NOTE
tidy_infant_hiv: no visible binding for global variable ‘ISO3’
tidy_infant_hiv: no visible binding for global variable ‘Countries’
tidy_infant_hiv: no visible binding for global variable ‘country’
tidy_infant_hiv: no visible binding for global variable ‘year’
```

- and if we choose "Build...Install and Restart", then run `tidy_infant_hiv("inst/extdata/infant_hiv.csv")`, we get:

```
Error in read_csv(src_path, skip = 2, na = c("-")) : 
  could not find function "read_csv"
```

- Look at `NAMESPACE`: no entries for the qualified names
- We need to add this:

```
#' @importFrom purrr map_dfr
#' @importFrom readr read_csv
#' @importFrom rlang .data
#' @importFrom stringr str_replace
```

- after check (which runs documentation) we have these extra lines in `NAMESPACE`

```
importFrom(purrr,map_dfr)
importFrom(readr,read_csv)
importFrom(rlang,.data)
importFrom(stringr,str_replace)
```

- But *still* getting errors

```
tidy_infant_hiv: no visible binding for global variable ‘ISO3’
tidy_infant_hiv: no visible binding for global variable ‘Countries’
tidy_infant_hiv: no visible binding for global variable ‘country’
tidy_infant_hiv: no visible binding for global variable ‘year’
Undefined global functions or variables:
  Countries ISO3 country year
```

- This required a bit more effort...
- Base R doesn't understand the way that tidyverse functions handle column names
- So add this to the header:

```
#' @importFrom rlang .data
```

and modify calls that use naked column names:

```
    select(-.data$ISO3, -.data$Countries) %>%
...
    select(.data$country, .data$year, everything())
...
    arrange(.data$country, .data$year)
```

- Clean build!
- Install and restart

- Then go back to the docs
  - `infant_hiv.R` and `unicefdata.R` to document dataset and package
  - The former "documents" a string
  - The latter "documents" `NULL`

## The Larger Problem

We have been given several more CSV files to clean up.
The first,
`raw/at_health_facilities.csv`,
shows the percentage of births at health facilities by country, year, and mother's age.
It comes from the same UNICEF website as our previous data,
but has a different set of problems.
Here are its first few lines:

```
,,GLOBAL DATABASES,,,,,,,,,,,,,
,,[data.unicef.org],,,,,,,,,,,,,
,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
Indicator:,Delivered in health facilities,,,,,,,,,,,,,,
Unit:,Percentage,,,,,,,,,,,,,,
,,,,Mother's age,,,,,,,,,,,
iso3,Country/areas,year,Total ,age 15-17,age 18-19,age less than 20,age more than 20,age 20-34,age 35-49,Source,Source year,,,,
AFG,Afghanistan,2010, 	33 , 	25 , 	29 , 	28 , 	31 , 	31 , 	31 ,MICS,2010,,,,
ALB,Albania,2005, 	98 , 	100 , 	96 , 	97 , 	98 , 	99 , 	92 ,MICS,2005,,,,
ALB,Albania,2008, 	98 , 	94 , 	98 , 	97 , 	98 , 	98 , 	99 ,DHS,2008,,,,
...
```

and its last:

```
ZWE,Zimbabwe,2005, 	66 , 	64 , 	64 , 	64 , 	67 , 	69 , 	53 ,DHS,2005,,,,
ZWE,Zimbabwe,2009, 	58 , 	49 , 	59 , 	55 , 	59 , 	60 , 	52 ,MICS,2009,,,,
ZWE,Zimbabwe,2010, 	64 , 	56 , 	66 , 	62 , 	64 , 	65 , 	60 ,DHS,2010,,,,
ZWE,Zimbabwe,2014, 	80 , 	82 , 	82 , 	82 , 	79 , 	80 , 	77 ,MICS,2014,,,,
,,,,,,,,,,,,,,,
Definition:,Percentage of births delivered in a health facility.,,,,,,,,,,,,,,
,"The indicator refers to women who had a live birth in a recent time period, generally two years for MICS and five years for DHS.",,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
Note:,"Database include reanalyzed data from DHS and MICS, using a reference period of two years before the survey.",,,,,,,,,,,,,,
,Includes surveys which microdata were available as of April 2016. ,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
Source:,"UNICEF global databases 2016 based on DHS, MICS .",,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
Contact us:,data@unicef.org,,,,,,,,,,,,,,
```

There are three files in this collection,
all exported from the same Excel spreadsheet.
Rather than writing a separate script for each,
we should create a tool that will handle them all.
At first glance,
the problems we need to solve to do this are:

1.  Each file may contain a different number of records,
    so our tool should select rows by content rather than by absolute row number.
2.  Each file may contain a different set of columns,
    so our tool should select those that always appear by name
    and somehow infer the location of the rest.

These two requirements will make our program significantly more complicated,
so we should tackle each with its own testable function.

## Testing

The standard testing library for R is [testthat][testthat].
Like Python's [unittest][unittest] library,
it is a member of the [xUnit][xunit] family
of [unit testing](../glossary/#unit-test) libraries:

1.  Each test consists of a single function that tests a single property or behavior of the system.
2.  Tests are collected into files with prescribed names that can be found by a [test runner](../glossary/#test-runner).
3.  Shared [setup](../glossary/#testing-setup) and [teardown](../glossary/#testing-teardown) steps are put in functions of their own.

Let's load it and write our first test:

```{r}
library(testthat)

test_that("Zero equals itself", { expect_equal(0, 0) })
```

As is conventional with xUnit-style testing libraries,
no news is good news:
if a test passes,
it doesn't produce output because it doesn't need our attention.
Let's try something that ought to fail:

```{r error=TRUE}
test_that("Zero equals one", { expect_equal(0, 1) })
```

Good:
we can draw some comfort from the fact that They have not yet changed the fundamental rules of arithmetic.
But what are the curly braces around `expect_equal` for?
The answer is that they create a code block of some sort for `test_that` to run.
We can run `expect_equal` on its own:

```{r error=TRUE}
expect_equal(0, 1)
```

but that doesn't produce a summary of how many tests passed or failed.
Passing a block of code to `test_that` also allows us to check several things in one test:

```{r error=TRUE}
test_that("Testing two things", {
  expect_equal(0, 0)
  expect_equal(0, 1)
})
```

Note that a block of code is *not* the same thing as an [anonymous function](../glossary/#anonymous-function),
which is why running this block of code does nothing:

```{r}
test_that("Using an anonymous function", function(){
  print("In our anonymous function")
  expect_equal(0, 1)
})
```

But running blocks of tests by hand is a bad practice no matter what is in them.
What we should do instead is put related tests in files,
then put those files in a directory called `tests`.
We can then run some or all of those tests with a single command.

To start,
let's create `tests/test_example.R`:

```{r code=readLines("tests/test_example.R"), eval=FALSE}
```

The first line loads the testthat package,
which gives us our tools.
The call to `context` on the second line gives this set of tests a name for reporting purposes.
After that,
we add as many calls to `test_that` as we want,
each with a name and a block of code.
We can now run this file from within RStudio:

```{r}
test_dir("tests")
```

A bit of care is needed when interpreting these results.
There are four `test_that` calls,
but eight actual checks,
and the number of successes and failures is counted by recording the results of the latter,
not the former.

What then is the purpose of `test_that`?
Why not just use `expect_equal` and its kin,
such as `expect_true`, `expect_false`, `expect_length`, and so on?
The answer is that it allows us to do one operation and then check several things afterward.
Let's create another file called `tests/test_tibble.R`:

```{r code=readLines("tests/test_tibble.R")}
```

(We don't actually have to call our test files `test_something.R`,
but `test_dir` and the rest of R's testing infrastructure expect us to.
Similarly,
we don't have to put them in a `tests` directory,
but gibbering incoherence is likely to ensue if we do not.)
Now let's run all of our tests:

```{r}
test_dir("tests")
```

That's rather a lot of output.
Happily,
we can provide a `filter` argument to `test_dir`:

```{r error=TRUE}
test_dir("tests", filter = "test_tibble.R")
```

Ah.
It turns out that `filter` is applied to filenames *after* the leading `test_` and the trailing `.R` have been removed.
Let's try again:

```{r}
test_dir("tests", filter = "tibble")
```

That's better,
and it illustrates our earlier point about the importance of following conventions.

## Warming Up

To give ourselves something to test,
let's create a file called `scripts/find_empty_01.R`
that defines a single function `find_empty_rows` that identifies all the empty rows in a CSV file.
Our first implementation is:

```{r code=readLines("scripts/find_empty_01.R")}
```

This is complex enough to merit line-by-line exegesis:

1.  Define the function with one argument `source`, from which we shall read.
2.  Read tabular data from that source and assign the resulting tibble to `data`.
3.  Begin a pipeline that will assign something to the variable `empty`.
    1.  Use `pmap` to map a function across each row of the tibble.
        Since we don't know how many columns are in each row,
        we use `...` to take any number of arguments.
    2.  Convert the variable number of arguments to a list.
    3.  Check to see if all of those arguments are either `NA` or the empty string.
    4.  Close the mapped function's definition.
4.  Start another pipeline.
    This one's result isn't assigned to a variable,
    so whatever it produces will be the value returned by `find_empty_rows`.
    1.  Construct a tibble that contains only the row numbers of the original table in a column called `id`.
    2.  Filter those row numbers to keep only those corresponding to rows that were entirely empty.
        The `as.logical` call inside `filter` is needed because the value returned by `pmap`
        (which we stored in `empty`)
        is a list, not a logical vector.
    3.  Use `pull` to get the one column we want from the filtered tibble as a vector.

There is a lot going on here,
particularly if you are (as I am at the time of writing)
new to R
and needed help to figure out that `pmap` is the function this problem wants.
But now that we have it,
we can do this:

```{r}
source("scripts/find_empty_01.R")
find_empty_rows("a,b\n1,2\n,\n5,6")
```

The `source` function reads R code from the given source.
Using this inside an RMarkdown file is usually a bad idea,
since the generated HTML or PDF won't show readers what code we loaded and ran.
On the other hand,
if we are creating command-line tools for use on clusters or in other batch processing modes,
and are careful to display the code in a nearby block,
the stain on our soul is excusable.

The more interesting part of this example is the call to `find_empty_rows`.
Instead of giving it the name of a file,
we have given it the text of the CSV we want parsed.
This string is passed to `read_csv`,
which (according to documentation that only took us 15 minutes to realize we had already seen)
interprets its first argument as a filename *or*
as the actual text to be parsed if it contains a newline character.
This allows us to write put the [test fixture](../glossary/#test-fixture)
right there in the code as a literal string,
which experience shows is to understand and maintain
than having test data in separate files.

Our function seems to work,
but we can make it more pipelinesque:

```{r code=readLines("scripts/find_empty_02.R")}
```

Going line by line once again:

1.  Define a function with one argument called `source`, from which we shall once again read.
2.  Read from that source to fill the pipeline.
3.  Map our test for emptiness across each row, returning a logical vector as a result.
    (`pmap_lgl` is a derivative of `pmap` that always casts its result to logical.
    Similar functions like `pmap_dbl` return vectors of other types,
    and many other tidyverse functions have strongly-typed variants as well.)
4.  Turn that logical vector into a single-column tibble,
    giving that column the name "empty".
    We explain the use of `.` below.
5.  Add a second column with row numbers.
6.  Discard rows that aren't empty.
7.  Return a vector of the remaining row IDs.

> **Wat?**
>
> Buried in the middle of the pipe shown above is the expression:
>
> `tibble(empty = .)`
>
> Quoting from *[Advanced R][advanced-r]*,
> "The function arguments look a little quirky
> but allow you to refer to `.` for one argument functions,
> `.x` and `.y.` for two argument functions,
> and `..1`, `..2`, `..3`, etc, for functions with an arbitrary number of arguments."
> In other words, `.` in tidyverse functions usually means "whatever is on the left side of the `%>%` operator",
> i.e., whatever would normally be passed as the function's first argument.
> Without this,
> we have no easy way to give the sole column of our newly-constructed tibble a name.

Here's our first batch of tests:

```{r code=readLines("tests/test_find_empty_a.R"), eval=FALSE}
```

And here's what happens when we run this file with `test_dir`:

```{r}
test_dir("tests", "find_empty_a")
```

This is perplexing:
we expected that if there were no empty rows,
our function would return `NULL`.
Let's look more closely:

```{r}
find_empty_rows("a\n1")
```

Ah:
we are being given an integer vector of zero length rather than `NULL`.
Let's have a closer look at the properties of this strange beast:

```{r}
print("is integer(0) equal to NULL")
integer(0) == NULL
print("any(logical(0))")
any(logical(0))
print("all(logical(0))")
all(logical(0))
```

All right.
If we compare `c(1L, 2L)` to `NULL`, we expect `c(FALSE, FALSE)`,
so it's reasonable to get a zero-length logical vector as a result when we compare `NULL` to an integer vector with no elements.
The fact that `any` of an empty logical vector is `FALSE` isn't really surprising either---none of the elements are `TRUE`,
so it would be hard to say that any of them are.
But `all` of an empty vector being `TRUE` is…unexpected.
The reasoning is apparently that none of the (nonexistent) elements are `FALSE`,
but honestly,
at this point we are veering dangerously close to [JavaScript Logic][javascrip-wat],
so we will accept this behavior and move on.

{% include links.md %}
